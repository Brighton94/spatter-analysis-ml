{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c562046",
   "metadata": {},
   "source": [
    "# YOLO-based Segmentation of Recoater Streaking & Spatter\n",
    "\n",
    "This notebook uses a pre-trained YOLOv8 segmentation model to detect recoater streaks and spatter\n",
    "in each layer of a Laser Powder Bed Fusion build. We then compute per-layer anomaly areas for\n",
    "downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da52d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from src.utils.yolo_segment import (\n",
    "    load_hdf5_slice,\n",
    "    load_hdf5_stack,\n",
    ")\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f4e42",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ecb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = os.path.abspath(\"../data/tcr_phase1_build2\")\n",
    "DATA_PATH     = os.path.abspath(\"../data/2021-04-16 TCR Phase 1 Build 2.hdf5\") \n",
    "CAMERA_PATH   = \"slices/camera_data/visible/0\"\n",
    "IMG_TRAIN_DIR = os.path.abspath(\"../data/tcr_phase1_build2/images/train\")\n",
    "LBL_TRAIN_DIR = os.path.abspath(\"../data/tcr_phase1_build2/labels/train\") \n",
    "DATA_YAML     = os.path.abspath(\"data.yaml\") \n",
    "\n",
    "# Classes\n",
    "CLASS_MAP = {1: \"spatter\", 2: \"streak\"}\n",
    "PIXEL_SIZE_MM2 = 0.01  # adjust to your calibration\n",
    "\n",
    "# YOLO parameters\n",
    "EPOCHS       = 5\n",
    "BATCH_SIZE   = 2\n",
    "IMG_SIZE     = 256\n",
    "CONF_THRESH  = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637da317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote /piml-in-metal-am/notebooks/data.yaml\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    \"path\": BASE,           # root for both images/ and labels/ (or masks/)\n",
    "    \"train\": \"images/train\", \n",
    "    \"val\":   \"images/val\",\n",
    "    \"nc\":    len(CLASS_MAP),\n",
    "    \"names\": list(CLASS_MAP.values()),\n",
    "}\n",
    "\n",
    "with open(DATA_YAML, \"w\") as f:\n",
    "    yaml.dump(cfg, f, sort_keys=False)\n",
    "print(\"Wrote\", DATA_YAML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af703b67",
   "metadata": {},
   "source": [
    "### Training with YOLO v11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c69b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "\traise RuntimeError(\"CUDA is not available. Please check your installation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd5f650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting YOLO model training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.140 ðŸš€ Python-3.13.3 torch-2.7.0+cu126 CUDA:0 (NVIDIA GeForce RTX 2070 with Max-Q Design, 7787MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=2, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=1, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/piml-in-metal-am/notebooks/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=True, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_v116, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=../runs/segment, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=../runs/segment/yolo_v116, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    683830  ultralytics.nn.modules.head.Segment          [2, 32, 64, [64, 128, 256]]   \n",
      "YOLO11n-seg summary: 203 layers, 2,842,998 parameters, 2,842,982 gradients, 10.4 GFLOPs\n",
      "\n",
      "Transferred 510/561 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 439.5Â±54.1 MB/s, size: 519.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /piml-in-metal-am/data/tcr_phase1_build2/labels/train.cache... 3027 images, 5 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3027/3027 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (28.7GB Disk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3027/3027 [00:00<00:00, 44398.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.1Â±0.2 ms, read: 198.2Â±30.3 MB/s, size: 480.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /piml-in-metal-am/data/tcr_phase1_build2/labels/val.cache... 534 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 534/534 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (5.1GB Disk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 534/534 [00:00<00:00, 51383.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to ../runs/segment/yolo_v116/labels.jpg... \n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Starting YOLO model training...\")\n",
    "try:\n",
    "    model = YOLO(\"yolo11n-seg.pt\")\n",
    "    \n",
    "    model.train(\n",
    "    data=\"data.yaml\",\n",
    "    epochs=5,\n",
    "    imgsz=256,\n",
    "    batch=2,\n",
    "    cache=False,        # **critical**\n",
    "    workers=2,\n",
    "    device=0,           # GPU 0\n",
    "    amp=True,\n",
    "    close_mosaic=0,\n",
    "    plots=False,\n",
    "    )\n",
    "    logger.info(\"Training completed successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(\"An error occurred during training:\", exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee534cd",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2511cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = load_hdf5_stack(H5_PATH, \"slices/camera_data/visible/0\")[:4]  # first 4 layers\n",
    "\n",
    "# run YOLOv11-Seg\n",
    "results = predict(model, imgs, imgsz=640, conf=0.25)\n",
    "\n",
    "# overlay first result\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(overlay_results(imgs[0], results[0]))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned = YOLO(\"runs/segment/yolo_spatter_streak/weights/best.pt\")\n",
    "# test on layer 0\n",
    "with h5py.File(DATA_PATH, \"r\") as h5:\n",
    "    img0 = load_hdf5_slice(DATA_PATH, 0, CAMERA_PATH)\n",
    "res0 = finetuned(img0, imgsz=IMG_SIZE, conf=CONF_THRESH)\n",
    "vis0 = visualize_detections(img0, res0)\n",
    "plt.imshow(vis0); plt.axis(\"off\"); plt.title(\"Layer 0 - Fine-tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e2775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) load full stack into memory (or chunk manually if too big)\n",
    "stack = load_hdf5_stack(DATA_PATH, CAMERA_PATH)  # shape (N,H,W,3)\n",
    "N = stack.shape[0]\n",
    "\n",
    "# 2) preallocate\n",
    "recoater_areas = np.zeros(N, dtype=float)\n",
    "spatter_areas  = np.zeros(N, dtype=float)\n",
    "\n",
    "# 3) run in batches\n",
    "for i in range(0, N, BATCH_SIZE):\n",
    "    batch = stack[i : i + BATCH_SIZE]\n",
    "    recoater_areas[i : i + BATCH_SIZE] = batch_predict_and_compute_areas(\n",
    "        finetuned, batch, [2], PIXEL_SIZE_MM2, imgsz=IMG_SIZE, conf=CONF_THRESH\n",
    "    )\n",
    "    spatter_areas[i : i + BATCH_SIZE] = batch_predict_and_compute_areas(\n",
    "        finetuned, batch, [1], PIXEL_SIZE_MM2, imgsz=IMG_SIZE, conf=CONF_THRESH\n",
    "    )\n",
    "    print(f\"Processed layers {i}â€“{i+BATCH_SIZE}\")\n",
    "\n",
    "# 4) assemble DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"layer\": np.arange(N),\n",
    "    \"recoater_mm2\": recoater_areas,\n",
    "    \"spatter_mm2\": spatter_areas,\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df.layer, df.recoater_mm2, label=\"Recoater\")\n",
    "plt.plot(df.layer, df.spatter_mm2, label=\"Spatter\")\n",
    "plt.xlabel(\"Layer\"); plt.ylabel(\"Anomaly Area (mmÂ²)\")\n",
    "plt.legend(); plt.title(\"Per-Layer Anomaly Areas\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
