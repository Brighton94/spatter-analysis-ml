{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7868f3c9",
   "metadata": {},
   "source": [
    "# 05 – Data Analysis & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e8737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from src.config import get_dataset_path\n",
    "from src.utils.feature_engineering import layer_dataframe\n",
    "from src.utils.part_anomaly import part_anomaly_fractions\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b310d05",
   "metadata": {},
   "source": [
    "The **build_features.py** file essentially converts a **.hdf5** file of a build into a **.csv** one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb541c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc65f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m src.utils.build_features \\\n",
    "#        --h5 \"../data/2021-04-16 TCR Phase 1 Build 2.hdf5\" \\\n",
    "#        --out \"../data/build2_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/build2_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeae07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb97741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layer = df[[\"layer\", \"gas_oxygen\", \"top_flow_rate\", \"spatter_px\", \"streak_px\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab28f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layer.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd7fe8",
   "metadata": {},
   "source": [
    "### 1. Oxygen spikes vs next‑layer spatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c36ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift O₂ up by one layer so current‑layer oxygen predicts next‑layer spatter\n",
    "df_q1 = (\n",
    "    df_layer\n",
    "    .assign(gas_oxygen_prev=df_layer[\"gas_oxygen\"].shift(0),\n",
    "            spatter_next   =df_layer[\"spatter_px\"].shift(-1))\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "r_oxy, p_oxy = pearsonr(df_q1[\"gas_oxygen_prev\"], df_q1[\"spatter_next\"])\n",
    "title_txt = (\n",
    "    \"O₂ level (layer L)  vs  Spatter pixels (layer L+1)\\n\"\n",
    "    f\"Pearson r = {r_oxy:.3f},   p = {p_oxy:.3g}\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.regplot(data=df_q1, x=\"gas_oxygen_prev\", y=\"spatter_next\",\n",
    "            scatter_kws={\"s\": 4}, truncate=True)\n",
    "plt.title(title_txt)\n",
    "plt.xlabel(\"Gas-loop O₂ [ppm]\")\n",
    "plt.ylabel(\"Spatter pixel count (next layer)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce15d615",
   "metadata": {},
   "source": [
    "### 2. Low top‑flow rates vs recoater streaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_layer[[\"top_flow_rate\", \"streak_px\"]].dropna()\n",
    "\n",
    "r_flow, p_flow = pearsonr(df_tmp[\"top_flow_rate\"], df_tmp[\"streak_px\"])\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.regplot(\n",
    "    data=df_tmp, x=\"top_flow_rate\", y=\"streak_px\",\n",
    "    scatter_kws={\"s\": 4}, truncate=True\n",
    ")\n",
    "plt.title(\n",
    "    \"Top flow rate  vs  Recoater-streak pixels\\n\"\n",
    "    f\"Pearson r = {r_flow:.3f},   p = {p_flow:.3g}\"\n",
    ")\n",
    "plt.xlabel(\"Top flow rate [L min⁻¹]\")\n",
    "plt.ylabel(\"Recoater streak pixel count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba0e45",
   "metadata": {},
   "source": [
    "### 3. Parts with lowest anomaly fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44de720",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(DATA_FILE, \"r\") as h5:\n",
    "    df_parts = part_anomaly_fractions(h5)\n",
    "\n",
    "df_parts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c7a3e9",
   "metadata": {},
   "source": [
    "### 4. Tall part anomaly trend vs build height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "TALL_PARTS       = df_parts.index[-5:]          # or pick any list of PIDs\n",
    "layers_per_chunk = 16                           # match dataset.chunks[0] if possible\n",
    "\n",
    "\n",
    "with h5py.File(DATA_FILE, \"r\") as h5:\n",
    "    ds_part = h5[\"slices/part_ids\"]\n",
    "    ds_spat = h5[\"slices/segmentation_results/8\"]\n",
    "\n",
    "    n_layers, H, W = ds_part.shape\n",
    "    P               = len(TALL_PARTS)\n",
    "    tall_pids       = np.asarray(TALL_PARTS, dtype=ds_part.dtype)\n",
    "\n",
    "    # output: rows = layer, cols = tall part IDs\n",
    "    layer_spatter = np.zeros((n_layers, P), dtype=np.int64)\n",
    "\n",
    "    # reusable read buffers (one HDF5 chunk)\n",
    "    part_buf = np.empty((layers_per_chunk, H, W), dtype=ds_part.dtype)\n",
    "    spat_buf = np.empty_like(part_buf, dtype=bool)\n",
    "\n",
    "    rng = tqdm(range(0, n_layers, layers_per_chunk),\n",
    "               total=(n_layers + layers_per_chunk - 1) // layers_per_chunk,\n",
    "               desc=\"Streaming layers\", unit=\"blk\")\n",
    "\n",
    "    for start in rng:\n",
    "        stop   = min(start + layers_per_chunk, n_layers)\n",
    "        sl_out = slice(0, stop - start)               # length in this chunk\n",
    "\n",
    "        ds_part.read_direct(part_buf, source_sel=slice(start, stop), dest_sel=sl_out)\n",
    "        ds_spat.read_direct(spat_buf, source_sel=slice(start, stop), dest_sel=sl_out)\n",
    "\n",
    "        # Broadcast compare: (P, L, H, W)  boolean\n",
    "        match_pid = (part_buf[np.newaxis, :sl_out.stop] == tall_pids[:, None, None, None])\n",
    "        # Logical AND with spatter mask, then sum pixels → shape (P, L)\n",
    "        counts = np.logical_and(match_pid, spat_buf[np.newaxis, :sl_out.stop]).sum(axis=(2, 3))\n",
    "\n",
    "        # counts.T is (L, P) so we can drop straight into the big table\n",
    "        layer_spatter[start:stop] += counts.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tall = pd.DataFrame(layer_spatter, columns=TALL_PARTS)\n",
    "df_cum  = df_tall.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58bb93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for pid in TALL_PARTS:\n",
    "    plt.plot(df_cum.index, df_cum[pid], label=f\"Part {pid}\")\n",
    "plt.xlabel(\"Layer number\")\n",
    "plt.ylabel(\"Cumulative spatter pixels [count]\")\n",
    "plt.title(\"Cumulative spatter vs build height (tall parts)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990db35e",
   "metadata": {},
   "source": [
    "### 5. Laser power / speed vs spatter occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61118bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(DATA_FILE, \"r\") as h5:\n",
    "    laser_power = h5[\"parts/process_parameters/laser_beam_power\"][:]\n",
    "    laser_speed = h5[\"parts/process_parameters/laser_beam_speed\"][:]\n",
    "\n",
    "df_params = pd.DataFrame(\n",
    "    {\n",
    "        \"anomaly_frac\": df_parts[\"anomaly_frac\"],\n",
    "        \"laser_power\":  laser_power[df_parts.index - 1],\n",
    "        \"laser_speed\":  laser_speed[df_parts.index - 1],\n",
    "    },\n",
    "    index=df_parts.index,\n",
    ")\n",
    "\n",
    "r_pwr, p_pwr = pearsonr(df_params[\"laser_power\"], df_params[\"anomaly_frac\"])\n",
    "r_spd, p_spd = pearsonr(df_params[\"laser_speed\"], df_params[\"anomaly_frac\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "\n",
    "sns.regplot(\n",
    "    data=df_params, x=\"laser_power\", y=\"anomaly_frac\",\n",
    "    truncate=True, scatter_kws={\"s\": 25}, ax=ax[0]\n",
    ")\n",
    "ax[0].set(\n",
    "    xlabel=\"Laser power [W]\",\n",
    "    ylabel=\"Anomaly fraction [–]\",\n",
    "    ylim=(-1, 1),\n",
    "    title=f\"Anomaly fraction vs laser power\\n\"\n",
    "          f\"Pearson r = {r_pwr:.3f},  p = {p_pwr:.3g}\",\n",
    ")\n",
    "\n",
    "sns.regplot(\n",
    "    data=df_params, x=\"laser_speed\", y=\"anomaly_frac\",\n",
    "    truncate=True, scatter_kws={\"s\": 25}, ax=ax[1]\n",
    ")\n",
    "ax[1].set(\n",
    "    xlabel=\"Scan speed [mm s$^{-1}$]\",\n",
    "    ylim=(-1, 1),\n",
    "    title=f\"Anomaly fraction vs scan speed\\n\"\n",
    "          f\"Pearson r = {r_spd:.3f},  p = {p_spd:.3g}\",\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a132426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity: compare 3 random parts\n",
    "for pid in np.random.choice(df_parts.index, 3, replace=False):\n",
    "    print(pid, laser_power[pid-1], laser_speed[pid-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df18a937",
   "metadata": {},
   "source": [
    "### 6. Recoater damage onset vs streak progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f39d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check if recoater‑health signal available, align with streak counts\n",
    "df_layer['streak_cumsum'] = df_layer['streak_px'].cumsum()\n",
    "df_layer[['layer', 'streak_px', 'streak_cumsum']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9638b972",
   "metadata": {},
   "source": [
    "## Physics Informed Extensions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013d13d",
   "metadata": {},
   "source": [
    "### 7. Predict *Under‑* and *Over‑Melting Area from Process Parameters\n",
    "\n",
    "Goal: Use only per‑part process parameters to estimate the fraction of surface classified as under melting or over melting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ee55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_ID_UNDER = 6\n",
    "CLASS_ID_OVER  = 7\n",
    "TARGET_RAM_MB  = 200                                  # keep buffers under this\n",
    "\n",
    "with h5py.File(DATA_FILE, \"r\") as h5:\n",
    "    ds_part  = h5[\"slices/part_ids\"]\n",
    "    ds_under = h5[f\"slices/segmentation_results/{CLASS_ID_UNDER}\"]\n",
    "    ds_over  = h5[f\"slices/segmentation_results/{CLASS_ID_OVER}\"]\n",
    "\n",
    "    nL, H, W = ds_part.shape\n",
    "\n",
    "    bytes_per_px = ds_part.dtype.itemsize + 2  # uint32 + two bool bytes\n",
    "    max_layers   = max(1, (TARGET_RAM_MB * 1024**2) // (bytes_per_px * H * W))\n",
    "    chunk_L      = min(ds_part.chunks[0] if ds_part.chunks else 16, max_layers)\n",
    "\n",
    "    max_pid_guess = int(ds_part.attrs.get(\"max_part_id\", 0)) or int(ds_part[:chunk_L].max())\n",
    "    total_px = np.zeros(max_pid_guess + 1, dtype=np.int64)\n",
    "    under_px = np.zeros_like(total_px)\n",
    "    over_px  = np.zeros_like(total_px)\n",
    "\n",
    "    part_buf  = np.empty((chunk_L, H, W), dtype=ds_part.dtype)\n",
    "    under_buf = np.empty_like(part_buf, dtype=bool)\n",
    "    over_buf  = np.empty_like(part_buf,  dtype=bool)\n",
    "\n",
    "    for start in tqdm(range(0, nL, chunk_L), desc=\"Scanning\", unit=\"blk\"):\n",
    "        stop   = min(start + chunk_L, nL)\n",
    "        n_here = stop - start\n",
    "        sl_out = slice(0, n_here)\n",
    "\n",
    "        ds_part.read_direct( part_buf,  slice(start, stop), sl_out)\n",
    "        ds_under.read_direct(under_buf, slice(start, stop), sl_out)\n",
    "        ds_over.read_direct( over_buf,  slice(start, stop), sl_out)\n",
    "\n",
    "        part_flat = part_buf[:n_here].ravel()          # view, no copy\n",
    "\n",
    "        total_px  += np.bincount(part_flat, minlength=total_px.size)\n",
    "\n",
    "        counts = np.bincount(\n",
    "            part_flat,\n",
    "            weights=under_buf[:n_here].ravel().astype(np.uint8),\n",
    "            minlength=total_px.size,\n",
    "        )\n",
    "        under_px += counts.astype(np.int64)\n",
    "        over_px  += np.bincount(\n",
    "            part_flat,\n",
    "            weights=over_buf[:n_here].ravel().astype(np.uint8),\n",
    "            minlength=total_px.size,\n",
    "        ).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = np.flatnonzero(total_px)\n",
    "valid = valid[valid != 0]                      # drop background\n",
    "\n",
    "df_melt = pd.DataFrame(\n",
    "    {\n",
    "        \"under_frac\": under_px[valid] / total_px[valid],\n",
    "        \"over_frac\": over_px[valid] / total_px[valid],\n",
    "    },\n",
    "    index=valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c634829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(DATA_FILE, \"r\") as h5:\n",
    "    power = h5[\"parts/process_parameters/laser_beam_power\"][:]\n",
    "    speed = h5[\"parts/process_parameters/laser_beam_speed\"][:]\n",
    "    hatch = h5[\"parts/process_parameters/hatch_spacing\"][:]\n",
    "\n",
    "df_melt[\"power\"] = power[df_melt.index - 1]     # 1-based IDs\n",
    "df_melt[\"speed\"] = speed[df_melt.index - 1]\n",
    "df_melt[\"hatch\"] = hatch[df_melt.index - 1]\n",
    "\n",
    "df_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d287e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = df_melt[['power', 'speed', 'hatch']]\n",
    "y_under = df_melt['under_frac']\n",
    "y_over  = df_melt['over_frac']\n",
    "\n",
    "model = LinearRegression()\n",
    "mae_under = -cross_val_score(model, X, y_under, cv=5, scoring='neg_mean_absolute_error').mean()\n",
    "mae_over  = -cross_val_score(model, X, y_over,  cv=5, scoring='neg_mean_absolute_error').mean()\n",
    "\n",
    "print(f'MAE (under‑melt frac) = {mae_under:.4f}')\n",
    "print(f'MAE (over‑melt  frac) = {mae_over:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbfb78",
   "metadata": {},
   "source": [
    "#### Visualising Response Surfaces\n",
    "Below we create 2‑D projections to see where the linear model (or raw data) suggests\n",
    "minimal melt‑pool anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff9c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of anomaly vs power & hatch spacing\n",
    "import matplotlib.tri as mtri\n",
    "\n",
    "triang = mtri.Triangulation(df_melt['power'], df_melt['hatch'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharex=True, sharey=True)\n",
    "\n",
    "for ax, target, title in zip(\n",
    "    axes,\n",
    "    ['under_frac', 'over_frac'],\n",
    "    ['Under‑melt fraction', 'Over‑melt fraction'],\n",
    "    strict=False\n",
    "):\n",
    "    tpc = ax.tricontourf(triang, df_melt[target], levels=14)\n",
    "    fig.colorbar(tpc, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Laser power [W]')\n",
    "    ax.set_ylabel('Hatch spacing [µm]')\n",
    "\n",
    "fig.suptitle('Anomaly fraction vs (Power, Hatch Spacing)')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86adbc4f",
   "metadata": {},
   "source": [
    "## 8. Physics‑Informed Analytics\n",
    "\n",
    "This section implements **first‑order physics models** directly on the build logs and\n",
    "segmentation outputs so we can test whether simple analytical theory aligns with observed anomalies.\n",
    "\n",
    "> **Disclaimer** &nbsp; All constants are ballpark values for 316 L steel and a Concept Laser M2‑class\n",
    "> machine. Adjust as needed for your exact material & machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical constants \n",
    "R_GAS = 8.314            # J·mol⁻¹·K⁻¹\n",
    "LAT_VAP = 6e6            # J·kg⁻¹  (approx latent heat of vaporisation)\n",
    "A_RECOIL = 1e5           # Pa – empirical scaling\n",
    "k_COND = 16              # W·m⁻¹·K⁻¹ thermal conductivity (solid, 316L)\n",
    "ALPHA = 4e-6             # m²·s⁻¹ thermal diffusivity\n",
    "LASER_RADIUS = 50e-6     # m (spot radius)\n",
    "ABSORPTIVITY = 0.35      # fraction of P coupled to substrate\n",
    "T_AMBIENT = 300          # K\n",
    "\n",
    "# Gas properties \n",
    "rho_Ar = 1.6             # kg·m⁻³ at ~100 °C\n",
    "rho_powder = 7800        # kg·m⁻³ (solid density proxy)\n",
    "NOZZLE_AREA = 1.0e-3     # m² (placeholder cross‑section)\n",
    "\n",
    "# Recoater properties \n",
    "L_BLADE = 0.25           # m (blade length)\n",
    "E_BLADE = 200e9          # Pa (steel modulus)\n",
    "I_BLADE = 1.5e-8         # m⁴ (estimated rectangular section)\n",
    "LAYER_THICKNESS = 50e-6  # m\n",
    "\n",
    "def rosenthal_Tmax(P: float, v: float, r: float = LASER_RADIUS) -> float:\n",
    "    \"\"\"Return peak melt‑pool surface temperature using a 2‑D Rosenthal approximation.\"\"\"\n",
    "    Q = ABSORPTIVITY * P  # effective absorbed power (W)\n",
    "    deltaT = Q / (2 * math.pi * k_COND * r) * math.exp(-v * r / (2 * ALPHA))\n",
    "    return T_AMBIENT + deltaT\n",
    "\n",
    "\n",
    "def recoil_pressure(T_surf: float) -> float:\n",
    "    \"\"\"Approximate recoil pressure from Clausius–Clapeyron‑like exponential.\"\"\"\n",
    "    return A_RECOIL * math.exp(-LAT_VAP / (R_GAS * T_surf))\n",
    "\n",
    "\n",
    "def plume_velocity(Q_l_min: float) -> float:\n",
    "    \"\"\"Argon volumetric flow `Q` (l/min) → plume advective velocity (m/s).\"\"\"\n",
    "    Q_m3_s = Q_l_min / 1000 / 60  # convert to m³/s\n",
    "    return Q_m3_s / NOZZLE_AREA * (1 - rho_powder / rho_Ar)\n",
    "\n",
    "\n",
    "def blade_deflection(F_tip: float) -> float:\n",
    "    \"\"\"Tip deflection of a cantilever blade with end load F.\"\"\"\n",
    "    return F_tip * L_BLADE**3 / (3 * E_BLADE * I_BLADE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c3f7b3",
   "metadata": {},
   "source": [
    "### 8.1 Melt‑Pool Physics → Spatter Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a87778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-part recoil pressure & correlate with anomaly fraction\n",
    "df_phys = df_melt.copy()\n",
    "\n",
    "# Directly merge anomaly_frac from df_params based on laser power and speed matching\n",
    "df_phys = pd.merge(df_phys, df_params, left_on=['power', 'speed'], right_on=['laser_power', 'laser_speed'], how='left')\n",
    "\n",
    "T_max_arr, P_recoil_arr = [], []\n",
    "for idx, row in df_phys.iterrows():\n",
    "    P, v = row['power'], row['speed']\n",
    "    Tmax = rosenthal_Tmax(P, v)\n",
    "    P_rec = recoil_pressure(Tmax)\n",
    "    T_max_arr.append(Tmax)\n",
    "    P_recoil_arr.append(P_rec)\n",
    "\n",
    "df_phys['Tmax_K'] = T_max_arr\n",
    "df_phys['P_recoil_Pa'] = P_recoil_arr\n",
    "df_phys['high_recoil'] = df_phys['P_recoil_Pa'] > 1.0e5  # P_crit = 1 bar\n",
    "\n",
    "print(df_phys[['power', 'speed', 'Tmax_K', 'P_recoil_Pa', 'anomaly_frac']].head())\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.boxplot(x='high_recoil', y='anomaly_frac', data=df_phys)\n",
    "plt.xlabel('P_recoil > 1 bar?')\n",
    "plt.ylabel('Spatter+Streak anomaly fraction')\n",
    "plt.title('High recoil pressure vs anomaly fraction')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a896540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae8ba9",
   "metadata": {},
   "source": [
    "### 8.2 Gas‑Flow Plume Velocity vs Spatter Dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf50d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate plume velocity per layer \n",
    "df_layer['plume_v_ms'] = df_layer['top_flow_rate'].apply(plume_velocity)\n",
    "\n",
    "corr_plume, p_value = pearsonr(df_layer['plume_v_ms'], df_layer['spatter_px'])\n",
    "print(f'Pearson r(plume_v, spatter_px) = {corr_plume:.3f}, p-value = {p_value:.3e}')\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.regplot(x='plume_v_ms', y='spatter_px', data=df_layer, scatter_kws={'s': 4})\n",
    "plt.xlabel('Plume advective velocity [m/s]')\n",
    "plt.ylabel('Spatter pixel count')\n",
    "plt.title(f'Gas plume vs spatter\\nPearson r = {corr_plume:.3f}, p-value = {p_value:.3e}')\n",
    "\n",
    "# Shorten axis values to scientific notation\n",
    "plt.ticklabel_format(axis='both', style='sci', scilimits=(0, 0))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7a112c",
   "metadata": {},
   "source": [
    "### 8.3 Recoater Blade Deflection vs Streak Onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use anomaly‑height proxy: streak pixels translate to tip load\n",
    "LOAD_PER_PX = 1e-3  # N per streak pixel (placeholder scaling)\n",
    "\n",
    "df_layer['tip_load_N'] = df_layer['streak_px'] * LOAD_PER_PX\n",
    "df_layer['blade_defl_m'] = df_layer['tip_load_N'].apply(blade_deflection)\n",
    "df_layer['exceeds_powder'] = df_layer['blade_defl_m'] > LAYER_THICKNESS\n",
    "\n",
    "prop_exceed = df_layer['exceeds_powder'].mean()\n",
    "print(f'%.1f%% of layers exceed powder thickness deflection' % (100*prop_exceed))\n",
    "\n",
    "sns.lineplot(x='layer', y='blade_defl_m', data=df_layer[::50])\n",
    "plt.axhline(LAYER_THICKNESS, c='r', ls='--', label='Powder layer height')\n",
    "plt.ylabel('Blade tip deflection [m]')\n",
    "plt.title('Recoater deflection across build')\n",
    "plt.legend();\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbca93c",
   "metadata": {},
   "source": [
    "### 8.4 Additional Metrics & Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166329e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt‑pool aspect ratio proxy \n",
    "df_phys['energy_density'] = df_phys['power'] / (df_phys['speed'] * df_phys['hatch'] * 50e-6)\n",
    "df_phys['aspect_ratio'] = 0.8 * np.sqrt(df_phys['energy_density']) / (0.2 * df_phys['energy_density'])\n",
    "\n",
    "corr_ar_under = df_phys['aspect_ratio'].corr(df_phys['under_frac'])\n",
    "corr_ar_over  = df_phys['aspect_ratio'].corr(df_phys['over_frac'])\n",
    "print(f'Aspect ratio vs under‑melt r = {corr_ar_under:.3f}')\n",
    "print(f'Aspect ratio vs over‑melt  r = {corr_ar_over :.3f}')\n",
    "\n",
    "# Cumulative energy density vs streak onset \n",
    "cum_ED = df_layer['spatter_px'].cumsum()  # proxy; replace with ED/time integral if logs exist\n",
    "sns.lineplot(x=df_layer['layer'], y=cum_ED)\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Cumulative spatter pixels (proxy ED)')\n",
    "plt.title('Cumulative energy proxy vs build height')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f2c7ce",
   "metadata": {},
   "source": [
    "### 9. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_selected.to_csv('../data/selected_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
