{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1032fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import os\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.datasets.multi_build import build_dataset_from_keys\n",
    "from src.models.segformer_baseline import load_model\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8eb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUILD_KEYS = [\"tcr_phase1_build1\", \"tcr_phase1_build2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b35a0c",
   "metadata": {},
   "source": [
    "### 1. Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c66af39",
   "metadata": {},
   "source": [
    "Just 10 layers for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ad729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build & split\n",
    "full_ds = build_dataset_from_keys(\n",
    "    # BUILD_KEYS, size=256, augment=True, layers=range(0, 100, 10)\n",
    "    BUILD_KEYS, size=256, augment=True, layers=None\n",
    ")\n",
    "\n",
    "\n",
    "val_split = 0.1\n",
    "n_val   = int(len(full_ds) * val_split)\n",
    "n_train = len(full_ds) - n_val\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "train_ds, val_ds = random_split(full_ds, [n_train, n_val], generator=g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e7f52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6423 713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256]) torch.Size([256, 256])\n"
     ]
    }
   ],
   "source": [
    "# sanity \n",
    "print(len(train_ds), len(val_ds))\n",
    "sample_img, sample_mask = train_ds[0]\n",
    "print(sample_img.shape, sample_mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ba872b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "#  Device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60844a0",
   "metadata": {},
   "source": [
    "### 2. Model & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0729a324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.13/site-packages/transformers/utils/deprecation.py:172: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
      "  return func(*args, **kwargs)\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([1, 256, 1, 1]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SegformerForSemanticSegmentation(\n",
       "  (segformer): SegformerModel(\n",
       "    (encoder): SegformerEncoder(\n",
       "      (patch_embeddings): ModuleList(\n",
       "        (0): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "          (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (block): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.014285714365541935)\n",
       "            (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.02857142873108387)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.04285714402794838)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (value): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.05714285746216774)\n",
       "            (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (value): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.0714285746216774)\n",
       "            (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.08571428805589676)\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.10000000149011612)\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): ModuleList(\n",
       "        (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode_head): SegformerDecodeHead(\n",
       "    (linear_c): ModuleList(\n",
       "      (0): SegformerMLP(\n",
       "        (proj): Linear(in_features=32, out_features=256, bias=True)\n",
       "      )\n",
       "      (1): SegformerMLP(\n",
       "        (proj): Linear(in_features=64, out_features=256, bias=True)\n",
       "      )\n",
       "      (2): SegformerMLP(\n",
       "        (proj): Linear(in_features=160, out_features=256, bias=True)\n",
       "      )\n",
       "      (3): SegformerMLP(\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (linear_fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ViT‐SegFormer\n",
    "processor, model = load_model()\n",
    "\n",
    "in_ch = model.decode_head.classifier.in_channels\n",
    "model.decode_head.classifier = nn.Conv2d(in_ch, 3, kernel_size=1)\n",
    "\n",
    "model.config.num_labels = 3\n",
    "model.config.id2label  = {0: \"background\", 1: \"streak\", 2: \"spatter\"}\n",
    "model.config.label2id  = {v: k for k, v in model.config.id2label.items()}\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef33477",
   "metadata": {},
   "source": [
    "### 4. Quick Epoch Run & History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fcd573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "with contextlib.suppress(ValueError):\n",
    "    model.gradient_checkpointing_enable() # saves VRAM\n",
    "\n",
    "model = torch.compile(model)                # PyTorch 2.x dynamic compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32bd2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../runs/segformer\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    # tf32=True,  # Disabled: causes ValueError if not supported by hardware\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    gradient_accumulation_steps=2,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    dataloader_num_workers=os.cpu_count(),\n",
    "    dataloader_pin_memory=True,\n",
    "    ddp_find_unused_parameters=False,\n",
    "    report_to=[\"mlflow\"],          # comment out if MLflow not set up\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn(batch):\n",
    "    imgs  = torch.stack([b[0] for b in batch])\n",
    "    masks = torch.stack([b[1] for b in batch])\n",
    "    return {\"pixel_values\": imgs, \"labels\": masks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7352aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny dataloader for visualization\n",
    "viz_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=min(2, os.cpu_count()),\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "imgs, masks = next(iter(viz_loader))\n",
    "imgs, masks = imgs.to(model.device), masks.to(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b26e407",
   "metadata": {},
   "source": [
    "### 5. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(trainer.state.log_history).dropna(subset=[\"epoch\"])\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(\n",
    "\tdf[\"epoch\"], \n",
    "\tdf[\"bce\"], \n",
    "\tlabel=\"BCE (val)\" if \"eval\" in df.columns else \"BCE\"\n",
    "\t)\n",
    "\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(\n",
    "\tdf[\"epoch\"], \n",
    "\tdf[\"mean_iou\"], \n",
    "\tlabel=\"mIoU\"\n",
    "\t)\n",
    "plt.title(\"Mean IoU\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132f005",
   "metadata": {},
   "source": [
    "### 6. Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()                         # IMPORTANT: disable dropout etc.\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(pixel_values=imgs).logits         # [B, C, H, W]\n",
    "    preds  = logits.argmax(dim=1).cpu().numpy()      # class map per pixel\n",
    "\n",
    "N = min(imgs.shape[0], 4)            # show at most 4 samples\n",
    "fig, axes = plt.subplots(N, 3, figsize=(12, 3 * N))\n",
    "\n",
    "rgba = {0: (0, 0, 0, 0.0),           # transparent background\n",
    "        1: (0, 0, 1, 0.4),           # streak is blue\n",
    "        2: (1, 0, 0, 0.4)}           # spatter is red\n",
    "\n",
    "for i in range(N):\n",
    "    ax_img, ax_gt, ax_pr = axes[i]\n",
    "\n",
    "    im = imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "    gt = masks[i].cpu().numpy()\n",
    "    pr = preds[i]\n",
    "\n",
    "    overlay_gt = np.zeros((*gt.shape, 4))\n",
    "    overlay_pr = np.zeros_like(overlay_gt)\n",
    "    for cls in (1, 2):\n",
    "        overlay_gt[gt == cls] = rgba[cls]\n",
    "        overlay_pr[pr == cls] = rgba[cls]\n",
    "\n",
    "    # image\n",
    "    ax_img.imshow(im)     \n",
    "    ax_img.set_title(\"Image\")             \n",
    "    ax_img.axis(\"off\")\n",
    "    # ground–truth\n",
    "    ax_gt.imshow(im)\n",
    "    ax_gt.imshow(overlay_gt)\n",
    "    ax_gt.set_title(\"Ground truth\")\n",
    "    ax_gt.axis(\"off\")\n",
    "    # prediction\n",
    "    ax_pr.imshow(im)\n",
    "    ax_pr.imshow(overlay_pr)\n",
    "    ax_pr.set_title(\"Prediction\")\n",
    "    ax_pr.axis(\"off\")\n",
    "\n",
    "fig.legend(\n",
    "    handles=[mpatches.Patch(color='blue', alpha=0.4, label='Streak'),\n",
    "             mpatches.Patch(color='red',  alpha=0.4, label='Spatter')],\n",
    "    loc=\"upper center\", ncol=2, frameon=False, bbox_to_anchor=(0.5, 1.05)\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
